<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://min-seong-kim.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://min-seong-kim.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-08-26T11:21:45+00:00</updated><id>https://min-seong-kim.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Machine Learning(2)</title><link href="https://min-seong-kim.github.io/blog/2025/machine-learning_2/" rel="alternate" type="text/html" title="Machine Learning(2)"/><published>2025-01-15T00:00:00+00:00</published><updated>2025-01-15T00:00:00+00:00</updated><id>https://min-seong-kim.github.io/blog/2025/machine-learning_2</id><content type="html" xml:base="https://min-seong-kim.github.io/blog/2025/machine-learning_2/"><![CDATA[<p>2025 겨울방학 Hail 스터디에서 배운 MLDL에 관한 내용</p> <ul> <li>3학년 2학기 딥러닝 강의 때 배운 내용</li> </ul>]]></content><author><name></name></author><category term="winter_study"/><category term="Machine_learning"/><summary type="html"><![CDATA[This is about the machine learning study Hail(human+artificial intelligence lab).]]></summary></entry><entry><title type="html">Machine Learning(1)</title><link href="https://min-seong-kim.github.io/blog/2025/machine-learning_1/" rel="alternate" type="text/html" title="Machine Learning(1)"/><published>2025-01-08T00:00:00+00:00</published><updated>2025-01-08T00:00:00+00:00</updated><id>https://min-seong-kim.github.io/blog/2025/machine-learning_1</id><content type="html" xml:base="https://min-seong-kim.github.io/blog/2025/machine-learning_1/"><![CDATA[<p>2025 겨울방학 Hail 스터디에서 배운 MLDL에 관한 내용</p> <ul> <li>3학년 2학기 딥러닝 강의 때 배운 내용</li> </ul> <h1 id="machine-learning">Machine learning</h1> <p>기계 학습은 일반적인 프로그래밍 방식과 다르다.</p> <p>일반적인 프로그래밍 방식은 Data를 미리 코딩된 프로그램에 넣어 computation을 통해 output을 출력하지만 기계 학습은 Training(정답인 input과 output set을 학습시킴)을 통해 만든 Program(aka “Model”)에 새로운 데이터를 넣었을 때 적절한 output을 출력한다.</p> <p>기계 학습은 크게 3가지로 분류된다.</p> <ul> <li>Supervised learning(지도 학습)</li> <li>Unsupervised learning(비지도 학습)</li> <li>Reinforcement learning(강화 학습)</li> </ul> <p>이전 딥러닝을 배우면서 지도 학습을 배웠고 이후 스터디에서 강화 학습에 대해 자세히 다루기 때문에 공부해보지 못한 비지도 학습을 더 깊게 공부해 보겠다.</p> <p><br/></p> <h2 id="supervised-learning">Supervised learning</h2> <p>지도 학습은 데이터의 input과 output을 아는 상태에서 둘 사이의 관계를 유형적으로 학습한다.</p> <h4 id="classification">Classification</h4> <p>분류는 각 데이터가 어떤 class에 속하는지 구분하는 작업이다. <br/> 정답값이 categorial한 변수라고 할 수 있다.</p> <p><strong>\(\hat{y} = \hat{f}(\mathbf{x})\)</strong></p> <p><code class="language-plaintext highlighter-rouge">x</code>: input으로 임의의 다차원 데이터(예: 사진, 텍스트) <br/> <code class="language-plaintext highlighter-rouge">y</code>: output으로 categorial한 데이터(예: 강아지, 고양이) <br/> \(\hat{f}\): 수학적으로 input x를 $\hat{y}$로 예측, 기계 학습을 가지고 학습시키고자 하는 모델</p> <p><br/></p> \[\mathcal{D} = \{(\mathbf{x}_i, y_i)\}_{i=1}^N\] <p><br/></p> <p>즉 분류는 위 input-output 데이터 셋을 Traning하여 \(y = \hat{y}\) 가 되도록 \(\hat{f}\)를 찾아내는 과정이다.</p> <p><br/></p> <h4 id="regression">Regression</h4> <p>회귀는 각 데이터가 어떤 continuous variable에 가까운지 예측하는 작업이다. <br/> 예측하기 때문에 정답값이 continuous한 변수라고 할 수 있다.</p> <p><strong>\(\hat{y} = \hat{f}(\mathbf{x})\)</strong></p> <p><code class="language-plaintext highlighter-rouge">x</code>: input으로 임의의 다차원 데이터(예: 자동차의 다양한 정보) <br/> <code class="language-plaintext highlighter-rouge">y</code>: output으로 continuos한 데이터(예: 자동차의 출력, 가격) <br/> \(\hat{f}\): 수학적으로 input x를 $\hat{y}$로 예측, 기계 학습을 가지고 학습시키고자 하는 모델</p> <p><br/></p> <p><strong>\(\mathcal{D} = \{(\mathbf{x}_i, y_i)\}_{i=1}^N\) input-output</strong></p> <p><br/></p> <table> <tbody> <tr> <td>회귀는 위 데이터 셋을 Traning하여 $$</td> <td>y - \hat{y}</td> <td>\(가 최소가 되게 하는(즉, 0이 되도록)\)\hat{f}$$를 찾아내는 과정으로 다음과 같이 요약할 수 있다.</td> </tr> </tbody> </table> <p><strong>\(\arg\min_{\hat{f}} (y - \hat{y})\)</strong></p> <table> <tbody> <tr> <td>**$$</td> <td>y - \hat{y}</td> <td>** 을 최소로 하는 argumnet <strong>\hat{f}$$</strong> 을 찾겠다.</td> </tr> </tbody> </table> <p><br/></p> <h2 id="unsupervised-learning">Unsupervised learning</h2> <p>비지도 학습은 데이터의 output을 모르는 상태에서 input의 흥미로운 특징(insteresting structure)을 무형적으로 찾아내는 것이다. <br/> 입력 데이터만 제공되고 그 데이터들을 기반으로 관계를 학습한다.</p> <h4 id="clustering"><strong>Clustering</strong></h4> <p>군집화는 데이터를 비슷한 것 끼리 짝지어 묶는 방법이다.</p> <p>Cluster는 Euclidean 거리와 코사인 유사도 등을 사용해 기준을 나누며 Cluster 내부 데이터는 서로 유사성이 높다고 볼 수 있다.</p> <p>가장 대표적인 알고리즘은 K-Means이다.</p> <h5 id="k-means-clustering"><em>K-Means Clustering</em></h5> <p>K-Means Clustering에서 K는 Cluster의 개수이며 Means는 평균을 의미한다. 이때 평균은 Cluster의 중심지로부터 데이터들 간의 거리의 평균을 나타낸다. <br/> 전체 과정은 5단계로 진행된다.</p> <hr/> <h6 id="-군집의-개수k-설정">① 군집의 개수(K) 설정</h6> <p>가장 먼저 Cluster의 개수를 정하는 것이다. Cluster의 개수를 어떻게 정하는지에 따라 학습 결과가 크게 변하므로 데이터에 따라 적절하게 Cluster의 개수를 정해야 한다. 이를 정하는 방법이 몇 가지 존재한다.</p> <p>1) Rule of Thumb</p> <p>이 방법은 가장 간단하고 빠른 방법으로 맨 처음 명확한 기준이 없을 경우에 사용하며 대략적으로 Cluster의 개수를 추정한다. <br/> 하지만 데이터 구조를 반영하지 못하므로 여러 관점에서 비효율적이다. <br/> 필요한 클러스터의 개수는 아래 식처럼 구할 수 있다.</p> <p><strong>\(k \approx \sqrt{\frac{n}{2}}\)</strong></p> <p><br/></p> <p>2) Elbow Method</p> <p>이 방법은 최적의 Cluster 개수 K를 시각적으로 확인하는 방법이다. <br/> Cluster를 늘리고 줄여가며 clustering의 결과를 최적으로 만드는 지점 엘보우(Elbow)에서 최적의 K를 찾는다. <br/> 선형 회귀에서 간단하게 배운 최소제고법과 비슷한 SSE(Sum of Squared Errors)를 사용한다.</p> <p><br/></p> <p><strong>\(SSE = \sum_{k=1}^{K} \sum_{x_i \in C_k} \|x_i - \mu_k\|^2\)</strong></p> <p><br/></p> <p>\(x_i\): Cluster: \(C_k\)에 속한 데이터 포인트 <br/> \(mu_k\): Cluster: \(C_k\)의 중심점</p> <p>위 식을 통해 Cluster 내 데이터 포인트와 중심점 간의 거리의 제곱의 합을 구한다. <br/> 이때 만약 K가 증가하면 Cluster가 세분화되어 각 데이터가 중심점에 가까워지므로 SSE가 감소한다. <br/> 이때 SSE의 감소율을 살펴보면서, 즉 K가 증가할 수록 감소율이 급격히 줄어드는 지점인 엘보우를 찾아 그 때의 K를 최적의 Cluster 개수로 간주한다. <br/> 이 방법은 SSE 함수를 통해 간단하고 직관적으로 최적의 Cluster 개수를 찾을 수 있지만 엘보우의 값을 구하면서 미분 시 후보 지점이 여러 개가 되거나 과적합이 생길 수 있으므로 추가적인 조치가 필요하다.</p> <p>3) Information Criterion Approach</p> <p>이 방식은 Cluster 모델의 적합성을 통계적으로 측정하는 방법으로 모델 복잡성(Complexity)과 데이터 적합성(fit) 간의 Trade-Off을 고려해 최적의 Cluster 개수 K를 구한다. <br/> Cluster 모델이 데이터를 잘 설명하려면 복잡한 구조가 필요하지만 과도하게 복잡해지면 과적합이 발생할 수 있다. <br/> 따라서 다음 두 항목을 평가한다. <br/> <code class="language-plaintext highlighter-rouge">적합성(Fit)</code>: 모델이 데이터를 얼마나 잘 설명하는지 <br/> <code class="language-plaintext highlighter-rouge">간결성(simplicity)</code>: 모델의 복잡성을 패널티로 추가해 과적합 방지</p> <p>(딥러닝 때 배운 과적합 방지 방법인 Weight decay과 비슷한 것 같다)</p> <p>평가 방법은 2가지로 아래와 같다. <em>AIC(Akaike Information Criterion)</em></p> <p><strong>\(AIC = -2 \cdot \log L + 2 \cdot p\)</strong></p> <ul> <li>모델의 log-likelihood와 모델의 복잡성 간의 균형을 평가</li> <li>값이 작을수록 더 적합한 모델</li> <li>K가 증가하면 모델의 log-likelihood도 증가하지만 모델 복잡성 패널티(2 ⋅ p)을 통해 과적합을 방지한다.</li> </ul> <p><em>BIC (Bayesian Information Criterion)</em></p> <p><strong>\(BIC = -2 \cdot \log L + \log(n) \cdot p\)</strong></p> <ul> <li>AIC 방식보다 데이터 샘플 크기(n)에 따른 더 큰 복잡성 패널티 부여</li> <li>BIC 값이 작을수록 더 나은 모델</li> <li>BIC는 AIC보다 간단한 모델을 선호(샘플 크기 𝑛이 클수록 복잡성 패널티가 커지기 때문)</li> </ul> <hr/> <h6 id="-초기-중심점-설정">② 초기 중심점 설정</h6> <p>1) Randomly select</p> <p>가장 기본적으로 무작위 방식을 통해 초기 중심점을 설정하는 방법이다.</p> <p>먼저 입력 데이터 <strong>\(X = \{ x_1, x_2, \dots, x_n \}\)</strong> 와 Cluster 개수 <strong>K</strong> 정의한다.</p> <p>이 데이터 집합 X에서 K개의 데이터 포인트를 무작위로 설정한다. <br/> 선택된 K개의 데이터 포인터는 초기 중심점 \(\mu_1, \mu_2, \dots, \mu_K\) 으로 설정된다. <br/> 이 때 중복된 데이터 포인트가 설정되면 안된다. <br/> 이제 선택된 데이터 포인트를 초기 중심점으로 고정하고 K-Means 알고리즘의 클러스터링 과정으로 넘어간다. <br/> 하지만 무작위로 선택되기 때문에 정확성이 낮고 지역 최저점 문제가 발생할 수 있다.</p> <p>2) K-Means++</p> <p>K-Means 알고리즘에서 실제 사용되는 초기 중심점 설정 방식으로 기존 Randomly select 방식보다 더 신중하게 초기 중심점을 선택한다. <br/> 먼저 첫 번째 중심점을 Randomly select 방식처럼 설정한다. <br/> 그럼 첫 번째 중심점 \(\mu_k\)이 설정된다. <br/> 이 때 각 데이터 포인트와 중심점 사이 간 거리를 계산한다. 각 데이터 포인트 \(X = \{ x_1, x_2, \dots, x_n \}\) 에 대해 가장 가까운 이미 선택된 중심점과의 거리를 구한다. <br/> 거리를 구하는 식은 아래와 같다.</p> <p><strong>\(D(x_i)^2 = \min_{1 \leq j \leq k} \| x_i - \mu_j \|^2\)</strong></p> <p>이제 각 데이터 포인트 \((\x_i\)\) 가 다음 중심점에서 선택될 확률은 \(D(x_i)^2\) 에 비례한다. <br/> 따라서 다음 식으로 확률을 구할 수 있다.</p> <p><strong>\(P(x_i) = \frac{D(x_i)^2}{\sum_{j=1}^n D(x_j)^2}\)</strong></p> <p>이 확률 분포에 근거해 데이터 포인트 중 하나를 무작위로 선택해 다음 중심점 \(u_2\) 을 설정한다.</p> <p>그러면 기존 Randomly select 방식과 다를 게 무엇인가? 라고 할 수 있지만 예시를 통해 설명해보겠다.</p> <p><strong>입력 데이터</strong>: <br/> 데이터 포인트: \(X = \{x_1, x_2, x_3, x_4\}\) <br/> 첫 번째 중심점: \(\mu_1 = x_1\)</p> <p><strong>데이터 포인트와 기존 중심점 사이의 거리 계산</strong>:</p> <ol> <li>\(D(x_1)^2 = 0\) (자기 자신은 중심점이므로 거리 0)</li> <li> \[D(x_2)^2 = 4\] </li> <li> \[D(x_3)^2 = 9\] </li> <li> \[D(x_4)^2 = 16\] </li> </ol> <p><strong>각 데이터 포인트의 확률 계산</strong>:</p> <p><strong>\(P(x_i) = \frac{D(x_i)^2}{\sum_{j=1}^n D(x_j)^2}\)</strong></p> <p><br/></p> <p>\(\sum_{j=1}^n D(x_j)^2 = 0 + 4 + 9 + 16 = 29\) \(P(x_1) = \frac{0}{29} = 0\) \(P(x_2) = \frac{4}{29} \approx 0.138\) \(P(x_3) = \frac{9}{29} \approx 0.310\) \(P(x_4) = \frac{16}{29} \approx 0.552\)</p> <p><br/></p> <p>그럼 확룰 분포 구간을 나타내면 <br/> \(x_1 : [0, 0)\) \(x_2 : [0, 0.138)\) \(x_3 : [0.138, 0.448)\) \(x_4 : [0.448, 1.0)\)</p> <p><br/></p> <p>0~1 사이 난수 r을 생성했을 때 나온 확률에 의해 데이터 포인트가 선택되므로 꽤 합리적이라 생각할 수 있다. <br/> 따라서 더 나은 초기 중심점을 선택할 수 있고 Randomly select에서 발생할 수 있는 지역 최저점 문제를 완화할 수 있다.</p> <hr/> <h6 id="-데이터를-cluster에-할당">③ 데이터를 Cluster에 할당</h6> <p>이제 각 데이터 포인트와 중심점 간의 거리를 계산해 그 결과 가장 가까운 중심점을 찾아 해당 중심점의 Cluster에 데이터 포인트를 배정한다.</p> <hr/> <h6 id="-cluster-중심점-재설정">④ Cluster 중심점 재설정</h6> <p>이제 해당 Cluster 내에서 더 정확한 중심점을 재설정할 것이다. <br/> Cluster 내 데이터 포인터들의 위치의 평균을 계산해 해당 위치를 중심점으로 재갱신한다. <br/> 이를 모든 Cluster에 대해 반복한다.</p> <hr/> <h6 id="-데이터를-cluster에-재할당중심점이-고정될-때가지-를-반복">⑤ 데이터를 Cluster에 재할당(중심점이 고정될 때가지 ④,⑤를 반복)</h6> <p>Cluster 내 데이터 포인트들의 위치가 더 이상 변하지 않을 때까지 위 단계들을 반복한다. <br/> 중심점의 위치가 재갱신될 때 근처의 데이터 포인트들이 다른 Cluster의 중심점에 더 가까워 질 수도 있으므로 계속 반복해 정확한 Cluster를 구현한다.</p> <hr/> <h4 id="dimensionality-reduction">Dimensionality Reduction</h4> <p>데이터 분석에서 차원은 데이터 셋의 특징들의 개수를 나타낸다.</p> <p>차원 축소는 데이터의 고차원 공간을 더 낮은 차원으로 변환하는 기법으로 데이터의 본진적인 구조나 중요한 특징을 유지하며 불필요한 정보를 제거하는 것을 목표로 한다.</p> <p>데이터를 압축하여 머신러닝의 시간을 줄일 수 있다.</p> <hr/> <h5 id="pca-principal-component-analysis">PCA (Principal Component Analysis)</h5> <p>PCA는 데이터를 압축하면서 데이터의 정보량(분산)을 최대한 많이 유지하는 차원 축소 기법이다.</p> <p>주로 통계와 머신러닝에서 데이터 전처리, 시각화, 특징 추출에 널리 사용된다.</p> <p><strong>핵심 아이디어</strong></p> <p>만약 물고기의 몸무게와 길이가 데이터 셋으로 들어온다고 생각해보자. <br/> 대체로 물고기의 몸무게와 길이는 비례된 연관성을 지닌다. <br/> 그렇다면 굳이 2개의 차원을 다 알 필요가 없다. <br/> 만약 비싼(큰) 물고기를 고르려면 몸무게와 길이가 통하는 \(mu\) 라는 축을 그린다. <br/> 축의 + 방향으로 가까워질수록 2개의 특징을 가늠할 수 있다. <br/> 측 차원으로 축소할 수 있다.</p> <p>이렇게 데이터의 분산을 최대화하는 방향으로 축을 설정한다.</p> <h6 id="-데이터-표준화">① 데이터 표준화</h6> <p><strong>\(z = \frac{x - \mu}{\sigma}\)</strong></p> <p>데이터의 각 차원을 평균 0, 표준편차 1로 스케일링한다.</p> <h6 id="-공분산-행렬-계산">② 공분산 행렬 계산</h6> <p><strong>\(\text{Cov}(X) = \frac{1}{n-1} X^\top X\)</strong></p> <p>표준화된 데이터의 공분산(데이터가 어떻게 변하는 지 나타냄) 행렬을 계산한다.</p> <h6 id="-고유값-및-고유-벡터-계산">③ 고유값 및 고유 벡터 계산</h6> <p>공분산 행렬의 고유값과 고유벡터를 계산한다.</p> <p><code class="language-plaintext highlighter-rouge">고유값</code>: 데이터의 분산 <br/> <code class="language-plaintext highlighter-rouge">고유벡터</code>: 주성분의 방향</p> <h6 id="-주성분-선택">④ 주성분 선택</h6> <p>고유값이 큰 순서대로 주성분을 정렬하고 원하는 차원만큼 선택한다.</p> <h6 id="-데이터-변환">⑤ 데이터 변환</h6> <p>선택된 고유벡터를 통해 원래 데이터를 투영한다.</p> <h2 id="reinforcement-learning">Reinforcement learning</h2> <p>위 두 가지 학습들은 주어진 데이터를 분석하고 학습하지만 강화 학습의 경우 직접 환경을 돌아다니며 학습한다.</p>]]></content><author><name></name></author><category term="winter_study"/><category term="Machine_learning"/><summary type="html"><![CDATA[This is about the machine learning study Hail(human+artificial intelligence lab).]]></summary></entry><entry><title type="html">Design Tradeoffs for SSD Performance</title><link href="https://min-seong-kim.github.io/blog/2024/Design-Tradeoffs-for-SSD-Perf/" rel="alternate" type="text/html" title="Design Tradeoffs for SSD Performance"/><published>2024-09-15T00:00:00+00:00</published><updated>2024-09-15T00:00:00+00:00</updated><id>https://min-seong-kim.github.io/blog/2024/Design-Tradeoffs-for-SSD-Perf</id><content type="html" xml:base="https://min-seong-kim.github.io/blog/2024/Design-Tradeoffs-for-SSD-Perf/"><![CDATA[<p>여름방학 FTL 스터디 때 공부한 SSD에 관한 논문인 Design Tradeoffs for SSD Performance에 대한 내용</p> <p><br/></p> <h1 id="introduction">Introduction</h1> <div style="display: flex; gap: 10px; justify-content: center;"> <div class="HDD" style="flex: 1;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/HDD-480.webp 480w,/assets/img/HDD-800.webp 800w,/assets/img/HDD-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/HDD.jpg" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="SSD" style="flex: 1;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/SSD-480.webp 480w,/assets/img/SSD-800.webp 800w,/assets/img/SSD-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/SSD.jpg" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>NAND Flash 기반 SSD는 기존에 사용한 HDD 보다 뛰어난 성능을 보여 컴퓨터 스토리지 구조에 큰 영향을 미쳤다.</p> <p><code class="language-plaintext highlighter-rouge">HDD</code>: 바이트 당 싼 가격, 더 큰 용량, 오래 사용 가능한 수명 <code class="language-plaintext highlighter-rouge">SSD</code>: HDD보다 뛰어난 대역폭, 속도, 랜덤 I/O 성능, 전력 절감, 내구성</p> <hr/> <p>SSD Design하면서 고려해야 할 특징들이 존재한다.</p> <ol> <li> <p><em>Data placement</em>: load balancing과 wear-leveling을 고려하여 SSD chip에 데이터를 위치시켜야 한다.</p> </li> <li> <p><em>Parallelism</em>: 특정 플래시 칩만으로는 최적의 성능을 낼 수 없기에 메모리 구성 요소들을 병렬로 작동시켜야 한다.</p> </li> <li> <p><em>Write Ordering</em>: NAND flash는 page 단위로 읽고 쓰고 block 단위로 삭제하기 때문에 삭제나 쓰기 작업 시 WAF(write amplification)가 발생할 수 있다. 때문에 쓰기 순서가 랜덤일 경우 성능 저하를 방지하기 위해 쓰기 순서를 효율적으로 관리해야 한다.</p> </li> <li> <p><em>Workload management</em>: SSD의 성능은 워크로드에 달려있다. 시퀀셜한 워크로드에서 좋은 성능을 보일 수 있지만 랜덤 워크로드에서는 좋지 않은 성능을 보일 수 있다.</p> </li> </ol> <h1 id="background">Background</h1> <div class="SSD Architecture"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/ssd_arch-480.webp 480w,/assets/img/ssd_arch-800.webp 800w,/assets/img/ssd_arch-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/ssd_arch.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <hr/> <div class="SSD Parelle Architecture"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/ssd_paralle-480.webp 480w,/assets/img/ssd_paralle-800.webp 800w,/assets/img/ssd_paralle-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/ssd_paralle.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>해당 모델은 2007년에 삼성에서 나온 NAND Flash 모델 K9XXG08UXM 이다.</p> <p>Single level cell(SLC) Flash 모델이며 다른 MLC TLC보다 성능과 수명이 길다.</p> <p>Flash Package의 크기는 4GB이고 Package마다 하나 이상의 다이를 가진다. <br/> 여러 패키지를 병렬로 사용해 데이터 처리 속도를 늘릴 수 있다.</p> <p>Die는 Package 내에서 독립적으로 작동하는 단위로 여러 Plane으로 구성된다. <br/> 각 Die는 칩 선택 라인과 Ready/Busy signal을 가지므로 한 Die가 Command를 받을 때 다른 Die는 Data 작업을 할 수 있다. <br/> 즉 각 Die마다 interleaving 작업이 가능하다.</p> <p>Die 내 존재하는 Plane에서도 병렬 작업이 되기 때문에 Plane을 독립적으로 작동할 수 있다.</p> <p>Block은 NAND Flash에서 삭제 단위이며 Page는 R/W의 단위이고 크기는 4KB이다.</p> <hr/> <div class="SSD Parelle Architecture"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Serial_Read-480.webp 480w,/assets/img/Serial_Read-800.webp 800w,/assets/img/Serial_Read-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Serial_Read.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Page를 Serial Read하는 과정</p> <ol> <li> <p>page를 레지스터로 읽어 드리는데 25us가 걸리고</p> </li> <li> <p>레지스터의 데이터를 Data bus를 통해 SSD Controller로 옮기는데 100us가 소모된다.</p> </li> <li> <p>총 소모 시간을 합하면 125us가 소모되며 이를 대역폭으로 나타내면 초당 32MB의 성능을 보여준다.</p> </li> </ol> <p>만약 인터리빙을 적용하면 데이터를 레지스터로 전송하는 시간(25µs) 동안 다른 페이지의 데이터를컨트롤러로 전송하는 작업을 병렬로 동시에 수행할 수 있기 때문에, 전체 작업 주기가 100µs로 줄어든다.</p> <div class="SSD Parelle Architecture"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Serial_Write-480.webp 480w,/assets/img/Serial_Write-800.webp 800w,/assets/img/Serial_Write-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Serial_Write.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Page를 serial Write하는 과정</p> <ol> <li> <p>Controller에서 레지스터로 데이터를 가져오는데 100us가 걸리며 레지스터에서 페이지로 데이터를 Write하는데 200us가 걸린다.</p> </li> <li> <p>총 소모 시간을 합하면 300us가 소모되며 이를 대역폭으로 나타내면 초당 13MB의 성능을 보여준다.</p> </li> </ol> <p>만약 인터리빙을 적용하면 컨트롤러에서 레지스터로 데이터를 전송하는 시간(100us)동안 쓰기 작업이 병렬로 동시에 수행할 수 있기 때문에 전체 작업 주기가 200us로 줄어든다.</p> <hr/> <div class="SSD Parelle Architecture"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Interleaving-480.webp 480w,/assets/img/Interleaving-800.webp 800w,/assets/img/Interleaving-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Interleaving.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>위 그림은 두 플래시 다이에 연결된 직렬 버스 핀을 사용해 4개의 소스 플래인과 4개의 목적지 플래인 사이에서 Page 복사를 인터리빙하는 과정을 보여준다.</p> <p>한 Plane에서 데이터가 전송되는 동안 다른 Plane에서 쓰기 작업이 진행되기 때문에 매 간격 즉 100us동안 쓰기 작업이 완료된다.</p> <p>이런 모습을 통해 동일 package에서는 다중 Read/Write이 좋은 성능을 보이는 것을 알 수 있다.</p> <p>이렇게 복사된 데이터들은 인터리빙된 패키지 간 복사와 유사한 성능을 보이지만 직렬 핀을 사용하지 않아 더 빠른 성능을 보여준다.</p> <h1 id="ssd-basics">SSD Basics</h1> <div class="SSD Parelle Architecture"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/ssd_arch_2-480.webp 480w,/assets/img/ssd_arch_2-800.webp 800w,/assets/img/ssd_arch_2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/ssd_arch_2.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>SSD의 전반적인 구조를 설명한다. <br/> 먼저 Host Interface logic에서는 USB나 SATA, PCLE 같은 물리 호스트 인터페이스와의 연결과 SSD의 FTL 기능을 지원하는 logical disk emulation를 지원한다.</p> <p>Buffer Manager에서는 보류 중이거나 유효한 요청들을 보관하는 역할을 하며 Multiplexer는 명령을 처리하고 serial bus를 따라 flash package에 대한 데이터 전송을 처리한다.</p> <p>Process는 명령의 흐름과 LBA에서 PBA로의 매핑을 관리한다.</p> <p>Mux는 여러 개의 입력 신호를 하나의 출력 신호로 결합, 즉 여러 패키지에서 데이터를 읽어올 때 이 데이터를 통합해 컨트롤러로 전송한다.</p> <p>Demux는 하나의 입력 신호를 여러 개의 입력 신호로 분할하는 역할이며 컨트롤러에서 보내는 데이터를 각각의 패키지로 분배해 병렬로 데이터를 작업한다.</p> <h3 id="allocation-pool">Allocation pool</h3> <p>SSD에서는 in place update가 불가능하고 load balance와 wear-leveling을 위해 LBA와 PBA간 매핑을 유지해야 한다. <br/> 그렇기 위해 쓰기 요청이 들어오면 어떤 블록을 할당할 지 고려하기 위해 Allocation pool의 추상화를 통해 mapping을 구성한다. <br/> 쓰기 요청을 처리할 때 들어오는 Logical Page는 미리 결정된 Allocation Pool에서 할당된다.</p> <p>Static map과 dynamic map은 allocation pool에서 매핑을 정적으로 동적으로 진행한다. <br/> 입력되는 Logical page의 size는 1KB부터 블록 크기인 256KB까지 정할 수 있으며 Logical page가 여러 패키지에 저장되어 병렬로 처리될 수 있는 Page span을 고려해야 한다.</p> <h3 id="three-constraints-for-variables">Three constraints for variables</h3> <p><code class="language-plaintext highlighter-rouge">Load balancing</code>: I/O작업이 allocation pool에서 균등하게 이루어져야합니다.</p> <p><code class="language-plaintext highlighter-rouge">Parallel access</code>: 여러 논리적 주소가 동시에 접근된다면, 이들을 각각 병렬로 접근할 수 있게 만들어야 한다.</p> <p><code class="language-plaintext highlighter-rouge">Block erase</code>: flash page는 overwrite가 불가능하므로 블록을 지우고 데이터를 써야 한다.</p> <p>Allocation pool을 정의하는 변수들과 3가지 제약 조건은 trade off 존재</p> <p>Static mapping ↑, load balancing ↓(병렬적으로 I/O를 처리하기 어려움) <br/> Span in same block -&gt; parallel access ↓ <br/> Logical Page size ↓ -&gt; 블록 내 페이지 개수 증가 GC 작업 시 더 많은 valid page를 식별하기 위해 데이터를 이동하는 작업량 증가 <br/> Logicla Page size ↑(block size) -&gt; 쓰기와 삭제 단위 같아서 삭제가 단순함 <br/> 하지만 logical page 보다 작은 크기의 쓰기는 read – modify – write로 이어짐</p>]]></content><author><name></name></author><category term="SSD"/><summary type="html"><![CDATA[This paper explores the various tradeoffs in solid state drive design]]></summary></entry><entry><title type="html">LevelDB Analysis of Deleted Record Restoration Techniques</title><link href="https://min-seong-kim.github.io/blog/2024/leveldb/" rel="alternate" type="text/html" title="LevelDB Analysis of Deleted Record Restoration Techniques"/><published>2024-09-15T00:00:00+00:00</published><updated>2024-09-15T00:00:00+00:00</updated><id>https://min-seong-kim.github.io/blog/2024/leveldb</id><content type="html" xml:base="https://min-seong-kim.github.io/blog/2024/leveldb/"><![CDATA[<p>대검찰청 과제를 하며 공부한 내용들</p> <p><br/></p> <h2 id="leveldb-architecture">LevelDB Architecture</h2> <p><br/></p> <p>LevelDB는 Google이 설계한 Key-Value 저장소로 빠르고 효율적인 데이터 읽기 및 쓰기 작업을 위해 설계된 오픈소스 데이터베이스이다. <br/> LevelDB의 간단한 구조를 살펴보겠다.</p> <p><br/></p> <div class="leveldb Architecture"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/leveldb_arch-480.webp 480w,/assets/img/leveldb_arch-800.webp 800w,/assets/img/leveldb_arch-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/leveldb_arch.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><br/></p> <p><strong>LevelDB</strong>는 LSM(Log-Structured Merge) Tree 구조를 기반으로한 Key-Value Store로 높은 쓰기 성능과 디스크 공간 효율성을 제공하며 위 그림처럼 MEM(MemTable), IMM(Immutable MemTable), SST(Sorted String Table), LOG 등으로 구성되어있다.</p> <p><code class="language-plaintext highlighter-rouge">MemTable</code>: LevelDB는 데이터를 우선 메모리에 저장한다. Key-Value 데이터 쌍을 SkipList 형태로 저장하며 Sort된 상태를 유지한다. 그리고 데이터가 가득 차면 IMM으로 전환되며 새 MEM을 생성한다. <br/> <code class="language-plaintext highlighter-rouge">Immutable MemTable</code>: 읽기 전용으로 변경된 MemTable이며 디스크로 Flush되기 전에 저장된 형태이다. <br/> <code class="language-plaintext highlighter-rouge">Flush</code>: IMM에 저장된 Key-Value 데이터 쌍을 디스크로 내보내는 과정으로 IMM을 SST 형태로 변환하여 디스크에 저장한다. <br/> <code class="language-plaintext highlighter-rouge">Sorted String Table</code>: SST는 여러 레벨로 나누어 관리되며 Level 0부터 데이터가 저장된다. Level 0에서는 IMM의 Key-Value 쌍이 바로 Flush되어 데이터 중복이 발생할 수 있지만 Level 1부터는 Compaction 과정을 거치며 중복된 데이터가 삭제된다. <br/> <code class="language-plaintext highlighter-rouge">Compaction</code>: 디스크에 저장된 여러 SST 파일을 병합하고 중복 데이터를 제거해 상위 레벨의 SST로 정리하는 과정이다. Compaction이 트리거되는 기준은 level 내 SST 파일이 일정 수(4개) 이상으로 생겼을 때, 또는 이후 level의 SST 파일의 크기가 임계값을 초과했을 때이다. 이후 SST들 간 겹치는 Key 범위를 선택하고 병합해 중복된 Key를 제거하고 정렬된 상태로 상위 level로 보낸다. <br/> <code class="language-plaintext highlighter-rouge">LOG</code>: 모든 쓰기 작업은 MEM에 저장되기 전 먼저 WAL(Write-Ahead Log)에 저장된다. 이는 비정상적인 종료 시 데이터 복구를 위해 사용되며 손상된 MEM을 복구할 수 있다.</p> <p><br/></p> <h2 id="sst-architecture">SST Architecture</h2> <p>LevelDB의 데이터 복구는 크게 메모리에서의 복구, 디스크에서의 복구로 구분할 수 있다. 먼저 디스크에서의 복구를 설명하기 위해 디스크에서 Key-Value가 저장되는 형태인 SST 구조를 더 자세하게 분석해보겠다.</p> <div class="SST Architecture"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/SST-480.webp 480w,/assets/img/SST-800.webp 800w,/assets/img/SST-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/SST.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><code class="language-plaintext highlighter-rouge">Data Block</code>: variable한 크기로(기본 4KB), Key와 Value 데이터 쌍을 저장하는 장소 <br/> <code class="language-plaintext highlighter-rouge">Filter Block</code>: variable한 크기로(기본 4KB), Data Block의 타켓 Key가 있는 지 유무 확인 <br/> <code class="language-plaintext highlighter-rouge">Metaindex Block</code>: variable한 크기로(기본 4KB), Filter Block의 메타 데이터 저장 <br/> <code class="language-plaintext highlighter-rouge">Index Block</code>: variable한 크기로(기본 4KB), Data Block의 메타 데이터 저장 <br/> <code class="language-plaintext highlighter-rouge">Footer</code>: variable한 크기로(기본 4KB), Metaindex/Index Block의 Block Handle 관리</p> <h2 id="entry-구조">Entry 구조</h2> <div class="SST Architecture"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/entry-480.webp 480w,/assets/img/entry-800.webp 800w,/assets/img/entry-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/entry.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><br/></p> <p>SSTable의 각 Block은 Block Builder 함수를 통해 생성하며 각 Block은 동일한 형식(Entry)으로 데이터를 저장되며 위와 같은 Entry 구조를 갖는다.</p> <h2 id="삭제-시나리오">삭제 시나리오</h2> <p>분석에 영향을 주는 요인은 배제</p> <ul> <li>Compression(데이터를 인코딩하여 압축하는 과정) 비활성화</li> <li>Filter 비활성화</li> </ul> <p>삽입:</p> <ul> <li>Key: KMS{n}</li> <li>Value: dankook_sslab{n}</li> <li>n: 0~400,000</li> </ul> <p>삭제</p> <ul> <li>KMS{n}에서 n의 범위가 0~120,000인 key</li> </ul> <hr/> <h3 id="leveldb에서-key-value-탐색-과정">LevelDB에서 Key-Value 탐색 과정</h3> <div class="SST Architecture"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/SSt_Data_block-480.webp 480w,/assets/img/SSt_Data_block-800.webp 800w,/assets/img/SSt_Data_block-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/SSt_Data_block.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>① Footer에서 Index Block의 Offset을 획득 <br/> ② Index Block의 Max Key에 따라 해당 Key의 Data Block Offset 획득 <br/> ③ Data Block의 Restart Point에 따라 적절한 Entry로 이동 <br/> ④ 해당하는 Key-Value 쌍 획득</p> <hr/> <h4 id="예시로-key-kms1-value-dankook_sslab1을-찾아가는-과정-분석">예시로 Key: KMS1, Value: dankook_sslab1을 찾아가는 과정 분석</h4> <h3 id="footer-구조">Footer 구조</h3> <div class="Cell Architecture" style="max-width: 50%; margin: auto;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/footer-480.webp 480w,/assets/img/footer-800.webp 800w,/assets/img/footer-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/footer.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><br/></p> <ul> <li>Block Handle format</li> <li>Offset: varint64</li> <li>Size: varint64</li> <li> <p>LevelDB에서 블록 데이터를 참조하는데 사용되는 구조</p> </li> <li>Meta Index Block’s index (char[p])</li> <li>Index Block’s index (char[q])</li> <li>Padding (char[40-p-q])</li> <li>Magic number (8B, fixed)</li> </ul> <p>Metaindex/Index Block의 Block Handle을 관리 <br/> 원하는 Key-Value 쌍을 얻기 위해선 Index Block의 내용을 알아야 하므로 Index Block의 Offset을 얻기 위해 Footer의 구조를 분석해야 한다.</p> <div class="Cell Architecture"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/footer_2-480.webp 480w,/assets/img/footer_2-800.webp 800w,/assets/img/footer_2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/footer_2.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><br/></p> <p>Footer size만큼 SSTable의 마지막 48Byte를 출력했다. <br/> Metaindex + Index block handle을 디코딩하면 Index Block handle의 Offset 획득 가능 <br/> 그리고 Index Block으로 이동한다.</p> <hr/> <h2 id="index-block-구조">Index Block 구조</h2> <p>Index Block은 Data Block의 메타 데이터를 저장한다. <br/> Data Block의 메타데이터를 알아야 Data Block으로 이동할 수 있으므로 Index Block을 분석해야 한다.</p> <div class="Cell Architecture"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Index_block-480.webp 480w,/assets/img/Index_block-800.webp 800w,/assets/img/Index_block-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Index_block.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><br/> 위에서 설명한 Block entry구조처럼 다음 키값을 가진다.</p> <ul> <li>Key: 해당 데이터 블록의 최대 키(Max Key)</li> <li>Value: 해당 데이터 블록의 Offset과 Size</li> </ul> <p><code class="language-plaintext highlighter-rouge">Shared key length</code>: 이전 키와 중복되는 키의 길이(아래 예시에서는 첫 키이므로 중복되는 부분이 없다)</p> <p><code class="language-plaintext highlighter-rouge">Unshared key length</code>: 이전 키와 중복되지 않는 키의 길이</p> <p><code class="language-plaintext highlighter-rouge">Value length</code>: Value의 길이</p> <p><code class="language-plaintext highlighter-rouge">Unshared key</code></p> <ul> <li>Max Key: KMS10117: 해당 데이터 블록에서 가장 큰 키</li> <li>index: 86 27 -&gt; little endian으로 바꾸면 2786 -&gt; 10118번째 key(시작이 KMS0)</li> </ul> <p><code class="language-plaintext highlighter-rouge">Value</code></p> <ul> <li>Data Block의 Offset과 Size를 가진 Block Handle로 구성</li> <li>Offset과 Size로 분류한 후 해당 Data Block으로 이동</li> </ul> <hr/> <h2 id="data-block-구조">Data Block 구조</h2> <div class="Cell Architecture"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Data_block_arch-480.webp 480w,/assets/img/Data_block_arch-800.webp 800w,/assets/img/Data_block_arch-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Data_block_arch.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Data Block은 Data Entry Block, Restart Point로 구성된다. <br/> <code class="language-plaintext highlighter-rouge">Data Entry Block</code>: 실제 Key와 Value 쌍이 저장 <br/> <code class="language-plaintext highlighter-rouge">Restart Point</code>: Data Block 내 키들을 효율적으로 검색하기 위한 각 Data Block Entry의 Offset의 모음</p> <p><br/></p> <p>Restart Point에서 KMS1이 존재하는 Data Entry Block으로 이동하기 위해 첫 번째 Offset인 0x 00 00 0 00으로 이동(key는 이미 정렬되어 있으므로)</p> <p>Data Block의 Restart Point에 따라 Entry로 이동 <br/> 각 Data Block Entry의 위치를 파악하기 위해 탐색 <br/> 4B 단위의 Restart Point를 분석 후 이동 <br/> KMS1을 찾기 위해선 첫 번째 Data Block Entry로 이동</p> <hr/> <div class="Cell Architecture"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/fdata_arch-480.webp 480w,/assets/img/fdata_arch-800.webp 800w,/assets/img/fdata_arch-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/fdata_arch.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>그러면 해당하는 Key-Value 쌍 획득 <br/> Key: KMS1 <br/> Value: dankook_sslab1</p> <p><code class="language-plaintext highlighter-rouge">Shared key length</code>: 3</p> <ul> <li>앞 키인 “KMS0”과 찾는 키인 “KMS1”에서 “KMS” 3글자가 중복됨(맨 앞 문자열부터 기준으로)</li> </ul> <p><code class="language-plaintext highlighter-rouge">Unshared key length</code>: 9</p> <ul> <li>앞 키인 “KMS0”과 찾는 키인 “KMS1”에서 “KMS” 뒤부터 1 + index가 중복되지 않은 key부분</li> </ul> <p><code class="language-plaintext highlighter-rouge">Value length</code>: 14</p> <ul> <li>dankook_sslab1의 길이</li> </ul> <p><code class="language-plaintext highlighter-rouge">Unshared key</code>:</p> <ul> <li>앞에 중복된 부분인 “KMS”는 생략된다.</li> <li>그 뒤 “1”이 오고 그 뒤에 index 부분이 포함된다.</li> <li>01 02: 01은 어떤 의미인지 모르겠으나 02는 두 번째 key를 나타낸다.</li> </ul> <hr/> <h2 id="delete가-이루어지는-과정">Delete가 이루어지는 과정</h2> <ol> <li>WriteBatch::Delete를 통한 Delete 요청 <ul> <li><code class="language-plaintext highlighter-rouge">rep_</code>: WriteBatch의 내부 버퍼이며 memtable에 삽입된다.</li> <li>Sequence: fixed64</li> <li>Count: fixed32</li> <li>Data: record[count]</li> </ul> </li> <li> <p>WriteBatch(req_)를 MemTable에 삽입</p> </li> <li>rep_에서 받은 record에 따라 MemTableInserter에서 Delete() 처리 <ul> <li>Record:</li> <li><code class="language-plaintext highlighter-rouge">kTypeValue</code> (삽입할 데이터의 타입), <code class="language-plaintext highlighter-rouge">kTypeDeletion</code> (삭제할 데이터의 타입)</li> </ul> </li> <li>MemTable에 삭제할 key에 대한 delete marker가 기록 <ul> <li>Delete 연산은 다음과 같은 정보로 처리</li> <li>Key: 삭제할 key</li> <li>Value: 빈 value</li> <li>Type: <code class="language-plaintext highlighter-rouge">kTypeDeletion</code> (삭제 명령)</li> </ul> </li> <li>같은 Level에서 Compaction이 이루어진다면 해당 key와 value는 제거</li> </ol> <hr/> <ul> <li><strong>Memtable에서 삭제된 키가 존재하는 경우</strong> <ul> <li>Memtable 내에서 즉각적으로 삭제되지 않는다.</li> <li>삭제됐음을 나타내는 Delete Marker를 추가되어 Memtable에 삽입</li> <li>Flush되는 시점에서도 그대로 내려온다.</li> </ul> </li> <li><strong>SSTable에서 삭제된 키가 존재하는 경우</strong> <ul> <li>Compaction 과정이 진행되어야 물리적으로 데이터가 삭제된다.</li> </ul> </li> </ul>]]></content><author><name></name></author><category term="Prosecution"/><category term="LevelDB"/><category term="forensics"/><summary type="html"><![CDATA[This is about the LevelDB forensics analysis by the prosecution.]]></summary></entry><entry><title type="html">SQLite Analysis of Deleted Record Restoration Techniques</title><link href="https://min-seong-kim.github.io/blog/2024/SQLite-Forensics/" rel="alternate" type="text/html" title="SQLite Analysis of Deleted Record Restoration Techniques"/><published>2024-08-20T00:00:00+00:00</published><updated>2024-08-20T00:00:00+00:00</updated><id>https://min-seong-kim.github.io/blog/2024/SQLite-Forensics</id><content type="html" xml:base="https://min-seong-kim.github.io/blog/2024/SQLite-Forensics/"><![CDATA[<p>WDSC 논문 발표를 준비하며 공부한 SQLite Forensics 내용들</p> <p><br/></p> <h2 id="sqlite-architecture">SQLite Architecture</h2> <p>다음 사진은 SQLite의 구조를 보여준다.</p> <div class="SQLite Architecture"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/SQLite_Architecture-480.webp 480w,/assets/img/SQLite_Architecture-800.webp 800w,/assets/img/SQLite_Architecture-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/SQLite_Architecture.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><br/></p> <p>SQLite는 페이지를 기본 단위로 사용하며 여러 개의 페이지로 구성되어 있다. <br/> <code class="language-plaintext highlighter-rouge">Database file header</code>: 데이터베이스의 전반적인 메타데이터를 저장하고 첫 페이지에만 존재 <br/> <code class="language-plaintext highlighter-rouge">Page header</code>: 페이지의 메타데이터를 저장 <br/> <code class="language-plaintext highlighter-rouge">Cell pointer array</code>: 페이지 내 각 셀의 위치를 저장 <br/> <code class="language-plaintext highlighter-rouge">Unallocated area</code>: 아직 할당되지 않은 공간 <br/> <code class="language-plaintext highlighter-rouge">Cell</code>: 실제 데이터를 저장하는 단위 <br/> <code class="language-plaintext highlighter-rouge">Reserved space</code>: 성능 최적화나 데이터 무결성을 위한 공간</p> <p><br/></p> <h2 id="cell-architecture">Cell Architecture</h2> <div class="Cell Architecture"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Cell_Architecture-480.webp 480w,/assets/img/Cell_Architecture-800.webp 800w,/assets/img/Cell_Architecture-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/Cell_Architecture.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><br/></p> <p>셀의 내부 구조를 살펴보면 <br/> <code class="language-plaintext highlighter-rouge">Cell header</code>: 셀의 크기와 레코드를 식별하는 Row ID를 저장 <br/> <code class="language-plaintext highlighter-rouge">Record header</code>: 헤더의 크기와 각 데이터 필드의 타입과 길이를 저장 <br/> <code class="language-plaintext highlighter-rouge">Data area</code>: 실제 데이터가 저장</p> <p><br/></p> <h2 id="deleted-record-recovery-technique">Deleted record recovery technique</h2> <p><br/></p> <h3 id="--free-page-list-analysis">- Free page list analysis</h3> <div class="Cell Architecture" style="max-width: 50%; margin: auto;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/free_page_list-480.webp 480w,/assets/img/free_page_list-800.webp 800w,/assets/img/free_page_list-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/free_page_list.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><br/></p> <p>Database 파일의 모든 프리 페이지는 리스트로 서로 연결되어 있고 삭제된 데이터를 포함하고 있다. <br/> 이 프리 페이지들을 분석하여 삭제된 레코드를 복원할 수 있다.</p> <p>아래는 삽입한 레코드이다.</p> <p><br/></p> <table> <thead> <tr> <th>Name</th> <th>Affiliation</th> <th>StudentID</th> </tr> </thead> <tbody> <tr> <td>KMS</td> <td>Dankook University1</td> <td>1</td> </tr> <tr> <td>LSH</td> <td>Dankook University2</td> <td>2</td> </tr> <tr> <td>…</td> <td>…</td> <td>…</td> </tr> <tr> <td>KVY</td> <td>Dankook University2999</td> <td>2999</td> </tr> <tr> <td>LYM</td> <td>Dankook University3000</td> <td>3000</td> </tr> </tbody> </table> <p><br/></p> <p>삭제된 데이터 흔적이 남아 있기 위해 SQLite 기능인 secure_delete를 비활성화하고 삭제 작업 진행</p> <p><br/></p> <p><code class="language-plaintext highlighter-rouge">sqlite&gt; PRAGMA secure_delete = 0;</code></p> <p><br/></p> <h3 id="database-file-header-analysis">Database file header analysis</h3> <p>아래 표는 Database file header에서 첫 40Byte의 구조를 보여준다.</p> <table> <thead> <tr> <th>Offset</th> <th>Size</th> <th>Description</th> </tr> </thead> <tbody> <tr> <td>0</td> <td>16</td> <td>Header string</td> </tr> <tr> <td>16</td> <td>2</td> <td>Page size</td> </tr> <tr> <td>18</td> <td>1</td> <td>File format write version</td> </tr> <tr> <td>19</td> <td>1</td> <td>File format read version</td> </tr> <tr> <td>20</td> <td>1</td> <td>Size of reserved space</td> </tr> <tr> <td>21</td> <td>1</td> <td>Maximum payload fraction</td> </tr> <tr> <td>22</td> <td>1</td> <td>Minimum payload fraction</td> </tr> <tr> <td>23</td> <td>1</td> <td>Leaf payload fraction</td> </tr> <tr> <td>24</td> <td>4</td> <td>File change counter</td> </tr> <tr> <td>28</td> <td>4</td> <td>Size of database file in pages</td> </tr> <tr> <td>32</td> <td>4</td> <td>Page number of the first free list trunk page</td> </tr> <tr> <td>36</td> <td>4</td> <td>Total number of free list pages</td> </tr> </tbody> </table> <p><br/></p> <p>이 표를 기반으로 .db 파일의 파일 헤더를 분석해보면</p> <p><br/></p> <p><code class="language-plaintext highlighter-rouge">$hd test.db</code></p> <div class="sql file Architecture"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/sql_file_header-480.webp 480w,/assets/img/sql_file_header-800.webp 800w,/assets/img/sql_file_header-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/sql_file_header.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><br/></p> <p>페이지의 크기, 첫번째 free list page의 페이지 번호, 전체 free list page의 개수를 알 수 있다.</p> <p><code class="language-plaintext highlighter-rouge">Address = (offset32 – 1) x 0x1000</code></p> <p>위 식을 통해 free list page(0x5000)으로 이동</p> <p><br/></p> <h4 id="free-page-header-analysis">Free page header analysis</h4> <p>아래 표는 Database file header에서 첫 40Byte의 구조를 보여준다.</p> <p><br/></p> <table> <thead> <tr> <th>Offset</th> <th>Size</th> <th>Description</th> </tr> </thead> <tbody> <tr> <td>0</td> <td>1</td> <td>B-tree page type</td> </tr> <tr> <td>1</td> <td>2</td> <td>Start of the first freeblock on the page</td> </tr> <tr> <td>3</td> <td>2</td> <td>Number of cells on the page</td> </tr> <tr> <td>5</td> <td>2</td> <td>Start of the cell content area</td> </tr> <tr> <td>7</td> <td>1</td> <td>Number of fragmented free bytes</td> </tr> <tr> <td>8</td> <td>4</td> <td>Right-most pointer</td> </tr> </tbody> </table> <p><br/> 페이지의 헤더를 통해 페이지의 형식, 페이지 내 셀의 개수, 첫 셀의 시작 주소 offse을 알 수 있다.</p> <div class="free page header Architecture"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/free_page_header_code-480.webp 480w,/assets/img/free_page_header_code-800.webp 800w,/assets/img/free_page_header_code-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/free_page_header_code.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><br/> 현재 주소인 0x5000에 시작 offse인 0x010c를 더하여 셀로 이동</p> <p><br/><br/></p> <h4 id="record-recovery">Record recovery</h4> <div class="free page header Architecture"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cell_code-480.webp 480w,/assets/img/cell_code-800.webp 800w,/assets/img/cell_code-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/cell_code.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><br/></p> <p>셀의 위치로 이동하면 각 셀의 헤더, 레코드 헤더, 데이터 영역을 확인할 수 있다.</p> <div class="free page header Architecture"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cell_code_2-480.webp 480w,/assets/img/cell_code_2-800.webp 800w,/assets/img/cell_code_2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/cell_code_2.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>셀 헤더를 통해 셀의 크기를 확인할 수 있고 레코드 헤더를 통해 헤더 사이드와 데이터의 타입과 길이를 이용해 삭제된 데이터가 포함된 페이지를 복원할 수 있다.</p> <p><br/> 아래 사진을 보면 실제 삽입한 studentID와 삭제된 값이 일치하는 모습을 확인할 수 있다.</p> <div class="free page header Architecture"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cell_code_3-480.webp 480w,/assets/img/cell_code_3-800.webp 800w,/assets/img/cell_code_3-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/cell_code_3.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p><br/></p> <h3 id="artifact-carving">Artifact carving</h3> <div class="free page header Architecture"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/ac_1-480.webp 480w,/assets/img/ac_1-800.webp 800w,/assets/img/ac_1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/ac_1.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>만약 프리 페이지 리스트 복원 방식에서 프리 페이지 리스트가 없거나 덮어 씌어진 경우 파일 곳곳에 저장된 slack space를 탐색해야 한다. 두 번째 복원 방식인 아티팩트 카빙은 파일 내 모든 공간을 검사하여 복원을 진행하는 방식이다. 이 기법은 데이터 베이스 파일 헤더와 레코드 헤더의 정보를 통해 삭제된 데이터에 대한 정보를 찾기 때문에 이 부분들이 덮어씌워진다면 패턴을 유추하는데 어려워 복구가 힘들다.</p> <p><br/></p> <div class="free page header Architecture"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/ac_2-480.webp 480w,/assets/img/ac_2-800.webp 800w,/assets/img/ac_2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/ac_2.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>하지만 문제가 생길 수 있는 시나리오가 있다. 기존 테이블을 삭제 후 같은 형식의 새로운 테이블을 생성하고 레코드를 삽입했다. 이때 새로 삽입된 데이터들이 기존 삭제된 데이터를 덮어 씌어진 것을 확인할 수 있다. 해당 시나리오는 아티팩트 카빙 작업을 통해 복원이 가능하나 파일 헤더 또는 레코드 헤더가 덮어씌어진 경우 정상적인 복원이 어렵다.</p> <p><br/></p> <h2 id="evaluation">Evaluation</h2> <p>기존에 진행한 실험들은 각 기법마다 어느 정도의 복원률을 보장하는 지 제공하지 않아 직접 기법들을 실험했다. <br/> 정확한 복원률을 확인하기 위해 Database viewer와 hex dump를 사용했다. <br/></p> <div class="Architecture" style="max-width: 50%; margin: auto;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/FQlite-480.webp 480w,/assets/img/FQlite-800.webp 800w,/assets/img/FQlite-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/FQlite.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>실험에서는 높은 복원률을 보이는 SQLite 복원 도구인 FQLite를 선택해 SQLite 포렌식 코퍼스에서 평가를 진행하였으며 기존 SQLite 포렌식 코퍼스는 5개의 범주로 구성되어 있다. 하지만 실험에서는 “삭제 및 덮어씌워진 내용”에 해당하는 범주를 이용해 평가하였고 세부 범주는 다음과 같은 5개의 카테고리로 나눠 살펴봤다.</p> <h4 id="sqlite-파일-생성-범주">SQLite 파일 생성 범주</h4> <p>ⓐDeleted table, ⓑdeleted and overwritten table, ⓒdeleted record, ⓓoverwritten record, ⓔdeleted overflow page</p> <table> <thead> <tr> <th>Categories</th> <th>Operations</th> </tr> </thead> <tbody> <tr> <td>0A-03</td> <td>create 2, insert 10/each, drop/each</td> </tr> <tr> <td>0B-02</td> <td>create 3, insert 10/each, drop 1, create 1, insert 5</td> </tr> <tr> <td>0C-02</td> <td>create 2 (int cols), insert 20/each, delete 5/each</td> </tr> <tr> <td>0D-03</td> <td>create, insert 10, delete 5, insert 10: match 1</td> </tr> <tr> <td>0E-02</td> <td>create, insert 20 (Overflow due to the insertion of large records, many columns), delete 5</td> </tr> </tbody> </table> <p><br/> 이때 삭제된 데이터 복원을 확인하기 위해 secure_delete를 비활성화하고 삭제 작업을 진행 <br/></p> <h3 id="실험-결과">실험 결과</h3> <table> <thead> <tr> <th>ID</th> <th>Undark</th> <th>SQLite Deleted Records Parser</th> <th>SQLabs SQLite Doctor</th> <th>Stellar Phoenix Repair for SQLite</th> <th>SysTools SQLite Database Recover</th> <th>Sanderson Forensic Browser for SQLite</th> <th>FQLite</th> <th>Free page</th> <th>Artifact Carving</th> </tr> </thead> <tbody> <tr> <td>0A-01</td> <td>20/20*</td> <td>0/20</td> <td>0/20</td> <td>0/20</td> <td>0/20</td> <td>0/20</td> <td>20/20</td> <td>0/20</td> <td>20/20</td> </tr> <tr> <td>0A-03</td> <td>20/20*</td> <td>0/20</td> <td>0/20</td> <td>0/20</td> <td>0/20</td> <td>0/20</td> <td>20/20</td> <td>10/20</td> <td>10/20</td> </tr> <tr> <td>0B-01*</td> <td>0/10</td> <td>0/10</td> <td>0/10</td> <td>0/10</td> <td>0/10</td> <td>0/10</td> <td>10/10</td> <td>5/10</td> <td>5/10</td> </tr> <tr> <td>0B-02</td> <td>0/10</td> <td>0/10</td> <td>0/10</td> <td>0/10</td> <td>0/10</td> <td>0/10</td> <td>10/10</td> <td>0/10</td> <td>10/10</td> </tr> <tr> <td>0C-01*</td> <td>0/7</td> <td>0/7</td> <td>0/7</td> <td>0/7</td> <td>0/7</td> <td>7/7</td> <td>7/7</td> <td>0/7</td> <td>7/7</td> </tr> <tr> <td>0C-02</td> <td>0/10</td> <td>0/10</td> <td>0/10</td> <td>0/10</td> <td>0/10</td> <td>10/10*</td> <td>10/10</td> <td>0/10</td> <td>10/10</td> </tr> <tr> <td>0D-01</td> <td>0/5</td> <td>2/5*</td> <td>0/5</td> <td>0/5</td> <td>0/5</td> <td>0/5</td> <td>5/5</td> <td>0/5</td> <td>5/5</td> </tr> <tr> <td>0D-03</td> <td>0/5</td> <td>0/5</td> <td>0/5</td> <td>0/5</td> <td>0/5</td> <td>0/5</td> <td>5/5</td> <td>0/5</td> <td>5/5</td> </tr> <tr> <td>0E-01</td> <td>3/7</td> <td>2/7</td> <td>0/7</td> <td>0/7</td> <td>0/7</td> <td>3/7</td> <td>7/7</td> <td>2/7</td> <td>5/7</td> </tr> <tr> <td>0E-02</td> <td>0/5</td> <td>0/5</td> <td>0/5</td> <td>0/5</td> <td>0/5</td> <td>0/5</td> <td>5/5</td> <td>0/5</td> <td>5/5</td> </tr> </tbody> </table> <p><br/> 실험 결과이다. <br/> 위 표는 SQLite 복원 방식 및 도구들의 복원율 상세 분석 결과를 보여준다. <br/> (*표시는 일부 복원 및 잘못된 복원이 포함된 경우) <br/></p> <hr/> <p>전반적인 결과를 확인해보면 프리 페이지 리스트를 통한 복원 기법이 아티팩트 카빙에 비해 복원률이 매우 낮은 것을 확인할 수 있다. 이는 대부분의 데이터베이스 파일 헤더에 프리 페이지에 대한 정보가 남아있지 않기 때문이다. 또한 Undartk나 SQLite Deleted Records Parser는 상대적으로 높은 복원률을 보였지만 대부분 잘못된 복원에 해당하는 경우가 많았다.</p> <hr/> <p>이때 아티팩트 카빙이 다른 범주에서는 복구율이 100%인 것에 비해 B-1 방식에서 복구율이 절반인 것을 확인할 수 있다. <br/> 이는 이전 아티팩트 카빙에서 보여준 시나리오처럼 데이터베이스 파일 헤더에 대한 정보가 없어 해당 레코드가 어디에 속해 있었는지 알 수 없기 때문이다.</p> <h5 id="recovery-rate-graph">Recovery Rate Graph</h5> <div class="Architecture" style="max-width: 50%; margin: auto;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/recovery_rate-480.webp 480w,/assets/img/recovery_rate-800.webp 800w,/assets/img/recovery_rate-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/recovery_rate.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>위 그림은 전 실험에서 진행한 복원 기법 별 복원율 그래프이다. <br/> 실험 결과는 프리 페이지 리스트의 경우 11.51% 정도 복원한 모습을 보이는 반면 아티팩트 카빙은 100%의 복원율을 보여줬다. <br/> 하지만 전에 말한 0B-01에서 보인 신뢰도 문제가 발생한다. <br/> 이 실험은 SQLite 포렌식 코퍼스에 한정된 실험 결과로 secure_delete가 수행되거나 안티 포렌식 기능인 Vacuum이 수행되면 모든 프리 리스트와 slack 공간이 회수되므로 복원이 불가능한 경우가 증가하게 된다.</p> <h5 id="recovery-performance-graph">Recovery Performance Graph</h5> <div class="Architecture" style="max-width: 60%; margin: auto;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/time_read-480.webp 480w,/assets/img/time_read-800.webp 800w,/assets/img/time_read-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/time_read.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>위 사진은 기법 별 성능 그래프이다. <br/> 이 실험은 아티팩트 카빙에서 덮어 씌어진 정도에 따라 복원 작업이 큰 차이를 보이므로 레코드 복원을 위한 페이지 헤더 획득까지의 과정을 수행하였다. <br/> 실험은 다음과 같은 환경에서 진행했다.</p> <table> <thead> <tr> <th>Component</th> <th>Specification</th> </tr> </thead> <tbody> <tr> <td>CPU</td> <td>12th Gen Intel(R) Core(TM) i7-12700H</td> </tr> <tr> <td>Memory</td> <td>16GB</td> </tr> <tr> <td>Database</td> <td>Chinook.db (15,607 lines, 1MB)</td> </tr> </tbody> </table> <hr/> <p><br/> 실험 결과 프리 페이지 리스트을 사용한 경우 아티팩트 카빙보가 약 32.34% 더 빠른 성능을 보였다. <br/> 그 이유는 아티팩트 카빙은 페이지 헤더가 손상되었을 가능성이 있어 추가 데이터 수집이 강제되기 때문입니다.</p> <p>하지만 이는 페이지 헤더만으로 판별 가능한 이상적인 경우이며 추가적인 셀 정보에 대한 작업이 필요한 경우 더 긴 작업 시간이 요구된다. <br/> 결과적으로 프리 페이지 리스트 및 페이지 유형에 대한 오프셋이 존재하는 경우 상대적으로 빠른 페이지 리스트 방식을 이요하고 이외 경우는 아티팩트 카빙을 적용하는 것이 효율적이다.</p>]]></content><author><name></name></author><category term="WDSC"/><category term="SQLite"/><category term="forensics"/><summary type="html"><![CDATA[This is about the sqlite forensics analysis published by WDSC.]]></summary></entry><entry><title type="html">2024 KCC</title><link href="https://min-seong-kim.github.io/blog/2024/tabs/" rel="alternate" type="text/html" title="2024 KCC"/><published>2024-06-28T00:00:00+00:00</published><updated>2024-06-28T00:00:00+00:00</updated><id>https://min-seong-kim.github.io/blog/2024/tabs</id><content type="html" xml:base="https://min-seong-kim.github.io/blog/2024/tabs/"><![CDATA[<p>This is how a post with <a href="https://github.com/Ovski4/jekyll-tabs">tabs</a> looks like. Note that the tabs could be used for different purposes, not only for code.</p> <h2 id="first-tabs">First tabs</h2> <p>To add tabs, use the following syntax:</p> <div class="language-liquid highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">{%</span><span class="w"> </span><span class="nt">tabs</span><span class="w"> </span><span class="nv">group-name</span><span class="w"> </span><span class="cp">%}</span>

<span class="cp">{%</span><span class="w"> </span><span class="nt">tab</span><span class="w"> </span><span class="nv">group-name</span><span class="w"> </span><span class="nv">tab-name-1</span><span class="w"> </span><span class="cp">%}</span>

Content 1

<span class="cp">{%</span><span class="w"> </span><span class="nt">endtab</span><span class="w"> </span><span class="cp">%}</span>

<span class="cp">{%</span><span class="w"> </span><span class="nt">tab</span><span class="w"> </span><span class="nv">group-name</span><span class="w"> </span><span class="nv">tab-name-2</span><span class="w"> </span><span class="cp">%}</span>

Content 2

<span class="cp">{%</span><span class="w"> </span><span class="nt">endtab</span><span class="w"> </span><span class="cp">%}</span>

<span class="cp">{%</span><span class="w"> </span><span class="nt">endtabs</span><span class="w"> </span><span class="cp">%}</span>
</code></pre></div></div> <p>With this you can generate visualizations like:</p> <ul id="log" class="tab" data-tab="ee2fbf39-772b-47aa-958b-79447278bce4" data-name="log"> <li class="active" id="log-php"> <a href="#">php </a> </li> <li id="log-js"> <a href="#">js </a> </li> <li id="log-ruby"> <a href="#">ruby </a> </li> </ul> <ul class="tab-content" id="ee2fbf39-772b-47aa-958b-79447278bce4" data-name="log"> <li class="active"> <div class="language-php highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">var_dump</span><span class="p">(</span><span class="s1">'hello'</span><span class="p">);</span>
</code></pre></div></div> </li> <li> <div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">console</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="dl">"</span><span class="s2">hello</span><span class="dl">"</span><span class="p">);</span>
</code></pre></div></div> </li> <li> <div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">pputs</span> <span class="dl">'</span><span class="s1">hello</span><span class="dl">'</span>
</code></pre></div></div> </li> </ul> <h2 id="another-example">Another example</h2> <ul id="data-struct" class="tab" data-tab="94041d60-68d1-42a5-8639-81dfc5a9e255" data-name="data-struct"> <li class="active" id="data-struct-yaml"> <a href="#">yaml </a> </li> <li id="data-struct-json"> <a href="#">json </a> </li> </ul> <ul class="tab-content" id="94041d60-68d1-42a5-8639-81dfc5a9e255" data-name="data-struct"> <li class="active"> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">hello</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s2">"</span><span class="s">whatsup"</span>
  <span class="pi">-</span> <span class="s2">"</span><span class="s">hi"</span>
</code></pre></div></div> </li> <li> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"hello"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">"whatsup"</span><span class="p">,</span><span class="w"> </span><span class="s2">"hi"</span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> </li> </ul> <h2 id="tabs-for-something-else">Tabs for something else</h2> <ul id="something-else" class="tab" data-tab="2ca1c30c-f0a2-4645-abd1-aff1bb74568b" data-name="something-else"> <li class="active" id="something-else-text"> <a href="#">text </a> </li> <li id="something-else-quote"> <a href="#">quote </a> </li> <li id="something-else-list"> <a href="#">list </a> </li> </ul> <ul class="tab-content" id="2ca1c30c-f0a2-4645-abd1-aff1bb74568b" data-name="something-else"> <li class="active"> <p>Regular text</p> </li> <li> <blockquote> <p>A quote</p> </blockquote> </li> <li> <p>Hipster list</p> <ul> <li>brunch</li> <li>fixie</li> <li>raybans</li> <li>messenger bag</li> </ul> </li> </ul>]]></content><author><name></name></author><category term="academic"/><summary type="html"><![CDATA[Korea Computer Congress 2024 [6.26-28], ICC Jeju]]></summary></entry><entry><title type="html">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</title><link href="https://min-seong-kim.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/" rel="alternate" type="text/html" title="Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra"/><published>2024-05-14T00:00:00+00:00</published><updated>2024-05-14T00:00:00+00:00</updated><id>https://min-seong-kim.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra</id><content type="html" xml:base="https://min-seong-kim.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[We’re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.]]></summary></entry><entry><title type="html">a post with typograms</title><link href="https://min-seong-kim.github.io/blog/2024/typograms/" rel="alternate" type="text/html" title="a post with typograms"/><published>2024-04-29T23:36:10+00:00</published><updated>2024-04-29T23:36:10+00:00</updated><id>https://min-seong-kim.github.io/blog/2024/typograms</id><content type="html" xml:base="https://min-seong-kim.github.io/blog/2024/typograms/"><![CDATA[<p>This is an example post with some <a href="https://github.com/google/typograms/">typograms</a> code.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">typograms
</span><span class="sb">+----+
|    |---&gt; My first diagram!
+----+</span>
<span class="p">```</span>
</code></pre></div></div> <p>Which generates:</p> <pre><code class="language-typograms">+----+
|    |---&gt; My first diagram!
+----+
</code></pre> <p>Another example:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">typograms
</span><span class="sb">.------------------------.
|.----------------------.|
||"https://example.com" ||
|'----------------------'|
| ______________________ |
||                      ||
||   Welcome!           ||
||                      ||
||                      ||
||  .----------------.  ||
||  | username       |  ||
||  '----------------'  ||
||  .----------------.  ||
||  |"*******"       |  ||
||  '----------------'  ||
||                      ||
||  .----------------.  ||
||  |   "Sign-up"    |  ||
||  '----------------'  ||
||                      ||
|+----------------------+|
.------------------------.</span>
<span class="p">```</span>
</code></pre></div></div> <p>which generates:</p> <pre><code class="language-typograms">.------------------------.
|.----------------------.|
||"https://example.com" ||
|'----------------------'|
| ______________________ |
||                      ||
||   Welcome!           ||
||                      ||
||                      ||
||  .----------------.  ||
||  | username       |  ||
||  '----------------'  ||
||  .----------------.  ||
||  |"*******"       |  ||
||  '----------------'  ||
||                      ||
||  .----------------.  ||
||  |   "Sign-up"    |  ||
||  '----------------'  ||
||                      ||
|+----------------------+|
.------------------------.
</code></pre> <p>For more examples, check out the <a href="https://google.github.io/typograms/#examples">typograms documentation</a>.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="diagrams"/><summary type="html"><![CDATA[this is what included typograms code could look like]]></summary></entry><entry><title type="html">a post that can be cited</title><link href="https://min-seong-kim.github.io/blog/2024/post-citation/" rel="alternate" type="text/html" title="a post that can be cited"/><published>2024-04-28T15:06:00+00:00</published><updated>2024-04-28T15:06:00+00:00</updated><id>https://min-seong-kim.github.io/blog/2024/post-citation</id><content type="html" xml:base="https://min-seong-kim.github.io/blog/2024/post-citation/"><![CDATA[<p>This is an example post that can be cited. The content of the post ends here, while the citation information is automatically provided below. The only thing needed is for you to set the <code class="language-plaintext highlighter-rouge">citation</code> key in the front matter to <code class="language-plaintext highlighter-rouge">true</code>.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="citation"/><summary type="html"><![CDATA[this is what a post that can be cited looks like]]></summary></entry><entry><title type="html">a post with pseudo code</title><link href="https://min-seong-kim.github.io/blog/2024/pseudocode/" rel="alternate" type="text/html" title="a post with pseudo code"/><published>2024-04-15T00:01:00+00:00</published><updated>2024-04-15T00:01:00+00:00</updated><id>https://min-seong-kim.github.io/blog/2024/pseudocode</id><content type="html" xml:base="https://min-seong-kim.github.io/blog/2024/pseudocode/"><![CDATA[<p>This is an example post with some pseudo code rendered by <a href="https://github.com/SaswatPadhi/pseudocode.js">pseudocode</a>. The example presented here is the same as the one in the <a href="https://saswat.padhi.me/pseudocode.js/">pseudocode.js</a> documentation, with only one simple but important change: everytime you would use <code class="language-plaintext highlighter-rouge">$</code>, you should use <code class="language-plaintext highlighter-rouge">$$</code> instead. Also, note that the <code class="language-plaintext highlighter-rouge">pseudocode</code> key in the front matter is set to <code class="language-plaintext highlighter-rouge">true</code> to enable the rendering of pseudo code. As an example, using this code:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">pseudocode
</span><span class="sb">% This quicksort algorithm is extracted from Chapter 7, Introduction to Algorithms (3rd edition)
\begin{algorithm}
\caption{Quicksort}
\begin{algorithmic}
\PROCEDURE{Quicksort}{$$A, p, r$$}
    \IF{$$p &lt; r$$}
        \STATE $$q = $$ \CALL{Partition}{$$A, p, r$$}
        \STATE \CALL{Quicksort}{$$A, p, q - 1$$}
        \STATE \CALL{Quicksort}{$$A, q + 1, r$$}
    \ENDIF
\ENDPROCEDURE
\PROCEDURE{Partition}{$$A, p, r$$}
    \STATE $$x = A[r]$$
    \STATE $$i = p - 1$$
    \FOR{$$j = p$$ \TO $$r - 1$$}
        \IF{$$A[j] &lt; x$$}
            \STATE $$i = i + 1$$
            \STATE exchange
            $$A[i]$$ with $$A[j]$$
        \ENDIF
        \STATE exchange $$A[i]$$ with $$A[r]$$
    \ENDFOR
\ENDPROCEDURE
\end{algorithmic}
\end{algorithm}</span>
<span class="p">```</span>
</code></pre></div></div> <p>Generates:</p> <pre><code class="language-pseudocode">% This quicksort algorithm is extracted from Chapter 7, Introduction to Algorithms (3rd edition)
\begin{algorithm}
\caption{Quicksort}
\begin{algorithmic}
\PROCEDURE{Quicksort}{$$A, p, r$$}
    \IF{$$p &lt; r$$}
        \STATE $$q = $$ \CALL{Partition}{$$A, p, r$$}
        \STATE \CALL{Quicksort}{$$A, p, q - 1$$}
        \STATE \CALL{Quicksort}{$$A, q + 1, r$$}
    \ENDIF
\ENDPROCEDURE
\PROCEDURE{Partition}{$$A, p, r$$}
    \STATE $$x = A[r]$$
    \STATE $$i = p - 1$$
    \FOR{$$j = p$$ \TO $$r - 1$$}
        \IF{$$A[j] &lt; x$$}
            \STATE $$i = i + 1$$
            \STATE exchange
            $$A[i]$$ with $$A[j]$$
        \ENDIF
        \STATE exchange $$A[i]$$ with $$A[r]$$
    \ENDFOR
\ENDPROCEDURE
\end{algorithmic}
\end{algorithm}
</code></pre>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="code"/><summary type="html"><![CDATA[this is what included pseudo code could look like]]></summary></entry></feed>